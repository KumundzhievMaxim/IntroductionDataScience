{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from typing import List\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will provide: \n",
    " - data explonatory \n",
    " - data insights\n",
    " - features selection \n",
    " - transforming dataset into required format (for further modelS applies)\n",
    "\n",
    "### TODO\n",
    "- find empty columns <-- there is no missing values\n",
    "\n",
    "## Assumed steps\n",
    "#### Benchmark\n",
    "    - dataset_v0\n",
    "        # EVALUATE \n",
    "        - [catboost_v0] untuned classifier on dataset_v0 data set (~75% accuracy)\n",
    "        - [catboost_v1] tuned classifier on dataset_v0 data set\n",
    "        \n",
    "####  Data set Preprocessing\n",
    "    - dataset_v1\n",
    "        - data cleaning\n",
    "            - ignore the tuples \n",
    "            - missing values\n",
    "                - fill with mean | meadian | custom\n",
    "            - elinimate noise data \n",
    "                - binning method & regression & clustering \n",
    "        - data transformation\n",
    "            - normalization\n",
    "            - attribute selection\n",
    "            - discretization\n",
    "        - data reduction\n",
    "        \n",
    "\n",
    "### CAVEATS \n",
    "- Imbalanced target (700 vs 300)\n",
    "- Odd mean loan of creditors age of > 65 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps\n",
    "1. Rename columns names for explicit visual understanding of features  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Transformer:\n",
    "    @staticmethod\n",
    "    def rename_columns(dataset: pd.DataFrame):\n",
    "        \"\"\"Rename dataframe columns names.\n",
    "        Notes:\n",
    "            target column names based on provided data_description.txt\n",
    "        Returns:\n",
    "            pd.DataFrame - dataframe with renamed columns \n",
    "        \"\"\"\n",
    "    \n",
    "        target_columns = {\n",
    "            'X01': 'account_status',\n",
    "            'X06': 'account_savings',\n",
    "            'X02': 'credit_duration',\n",
    "            'X03': 'credit_history',\n",
    "            'X04': 'credit_purpose',\n",
    "            'X05': 'credit_amount',\n",
    "            'X07': 'employment_status',\n",
    "            'X17': 'employment_description',\n",
    "            'X08': 'income_installment_rate',\n",
    "            'X09': 'gender_status',\n",
    "            'X10': 'credit_guarantors',\n",
    "            'X11': 'residence',\n",
    "            'X12': 'owned_property',\n",
    "            'X13': 'age',\n",
    "            'X14': 'installment_plans',\n",
    "            'X15': 'accomondation_type',\n",
    "            'X16': 'credit_existing_number',\n",
    "            'X18': 'liable_maintain',\n",
    "            'X19': 'phone_number',\n",
    "            'X20': 'foreign_worker',\n",
    "            'Y': 'y'\n",
    "        }\n",
    "        return dataset.rename(columns=target_columns)    \n",
    "    \n",
    "    @staticmethod\n",
    "    def categorical_columns(dataset: pd.DataFrame):\n",
    "        \"\"\"Within dataset find categorical columns\n",
    "        \n",
    "        Returns:\n",
    "          List: list of names of categorical columns.\n",
    "        \"\"\"\n",
    "        categorical_columns_indexes = []\n",
    "        \n",
    "        columns = dataset.columns\n",
    "        num_columns = dataset._get_numeric_data().columns # get numerical columns\n",
    "        \n",
    "        categorical_columns = sorted(list(set(columns) - set(num_columns)))\n",
    "        categorical_columns_indexes = [df.columns.get_loc(column) for column in categorical_columns]\n",
    "        return categorical_columns, categorical_columns_indexes\n",
    "        \n",
    "    \n",
    "    @staticmethod\n",
    "    def cast_categorical_column(column: pd.Series):\n",
    "        pass\n",
    "    \n",
    "    @staticmethod\n",
    "    def train_test_split(dataset: pd.DataFrame, test_size: int, shuffle=False):\n",
    "        from sklearn.model_selection import train_test_split\n",
    "        print(f'Splitting dataset {dataset.shape} with test_size :{test_size}')\n",
    "        X = dataset.drop(columns=['y'])\n",
    "        y = dataset['y']\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=shuffle, test_size=test_size)\n",
    "        print(f'X_train: {X_train.shape}')\n",
    "        print(f'y_train: {y_train.shape}')\n",
    "        print(f'X_test: {X_test.shape}')\n",
    "        print(f'y_test: {y_test.shape}')\n",
    "        return X_train, X_test, y_train, y_test\n",
    "    \n",
    "    @staticmethod\n",
    "    def data_cleaning(dataframe: pd.DataFrame):\n",
    "        \"\"\"Applies follwoing transformations:   \n",
    "            - data cleaning\n",
    "                - ignore the tuples # when the dataset is large and multiple values are missing within a tuple.\n",
    "                - missing values\n",
    "                    - fill with mean | meadian | custom\n",
    "                - encoding\n",
    "                - elinimate noise data \n",
    "                    - binning method & regression & clustering \n",
    "        \"\"\"\n",
    "        categorical_columns = [column for column in dataset_v1.columns if dataset_v1[f'{column}'].dtype == 'object']\n",
    "    \n",
    "        for column_name in categorical_columns: \n",
    "            labels = dataframe[f'{column_name}'].astype('category').cat.categories.tolist()\n",
    "            replace_map_comp = {f'{column_name}' : {k: v for k,v in zip(labels,list(range(1,len(labels)+1)))}}\n",
    "            dataframe.replace(replace_map_comp, inplace=True)\n",
    "        return dataframe\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Models:\n",
    "    @staticmethod\n",
    "    def _catboost_classifier(X_train, X_test, y_train, y_test, cat_features, **kwargs):\n",
    "        \"\"\"CatBoost Classifier.\n",
    "        \n",
    "        Notes:\n",
    "          - cat_features: CatBoost model requires list of indexes which denote categorical columns;\n",
    "        \"\"\"\n",
    "        \n",
    "        from catboost import CatBoostClassifier, Pool\n",
    "        from sklearn.metrics import accuracy_score\n",
    "        \n",
    "        train_data = Pool(\n",
    "            data=X_train.values,\n",
    "            label=y_train,\n",
    "            cat_features=cat_features\n",
    "        )\n",
    "        model = CatBoostClassifier(iterations=30)\n",
    "        model.fit(train_data)\n",
    "        predictions = model.predict(X_test.values)\n",
    "        accuracy = accuracy_score(y_test, predictions)\n",
    "        return accuracy\n",
    "    \n",
    "    @staticmethod\n",
    "    def _xgboost_classifier(X_train, X_test, y_train, y_test, **kwargs):\n",
    "        \"\"\"Apply XGBoost Classifier.\n",
    "        Notes:\n",
    "          When using XGBoost we need to convert categorical variables into numeric.\n",
    "        \"\"\"\n",
    "        from xgboost import XGBClassifier\n",
    "        from sklearn.metrics import accuracy_score\n",
    "        \n",
    "        model = XGBClassifier()\n",
    "        model.fit(X_train, y_train, verbose=True)\n",
    "        predictions = model.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, predictions)\n",
    "        return accuracy\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entry Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting dataset (1000, 21) with test_size :0.2\n",
      "X_train: (800, 20)\n",
      "y_train: (800,)\n",
      "X_test: (200, 20)\n",
      "y_test: (200,)\n",
      "Learning rate set to 0.233364\n",
      "0:\tlearn: 0.6137307\ttotal: 4.23ms\tremaining: 123ms\n",
      "1:\tlearn: 0.5945648\ttotal: 5.8ms\tremaining: 81.2ms\n",
      "2:\tlearn: 0.5614867\ttotal: 8.6ms\tremaining: 77.4ms\n",
      "3:\tlearn: 0.5243177\ttotal: 12.2ms\tremaining: 79ms\n",
      "4:\tlearn: 0.5066539\ttotal: 15.9ms\tremaining: 79.5ms\n",
      "5:\tlearn: 0.4876814\ttotal: 19.5ms\tremaining: 77.9ms\n",
      "6:\tlearn: 0.4826167\ttotal: 22.2ms\tremaining: 72.9ms\n",
      "7:\tlearn: 0.4735014\ttotal: 25.2ms\tremaining: 69.4ms\n",
      "8:\tlearn: 0.4643574\ttotal: 28.9ms\tremaining: 67.5ms\n",
      "9:\tlearn: 0.4500081\ttotal: 31.8ms\tremaining: 63.6ms\n",
      "10:\tlearn: 0.4366963\ttotal: 35.8ms\tremaining: 61.8ms\n",
      "11:\tlearn: 0.4300341\ttotal: 39.5ms\tremaining: 59.2ms\n",
      "12:\tlearn: 0.4215742\ttotal: 42.6ms\tremaining: 55.7ms\n",
      "13:\tlearn: 0.4011467\ttotal: 46ms\tremaining: 52.6ms\n",
      "14:\tlearn: 0.3883355\ttotal: 49.1ms\tremaining: 49.1ms\n",
      "15:\tlearn: 0.3776986\ttotal: 52ms\tremaining: 45.5ms\n",
      "16:\tlearn: 0.3669613\ttotal: 55ms\tremaining: 42ms\n",
      "17:\tlearn: 0.3619475\ttotal: 58.2ms\tremaining: 38.8ms\n",
      "18:\tlearn: 0.3591199\ttotal: 61.5ms\tremaining: 35.6ms\n",
      "19:\tlearn: 0.3491471\ttotal: 65ms\tremaining: 32.5ms\n",
      "20:\tlearn: 0.3445504\ttotal: 69ms\tremaining: 29.6ms\n",
      "21:\tlearn: 0.3411896\ttotal: 72.1ms\tremaining: 26.2ms\n",
      "22:\tlearn: 0.3312908\ttotal: 74.6ms\tremaining: 22.7ms\n",
      "23:\tlearn: 0.3302336\ttotal: 77ms\tremaining: 19.3ms\n",
      "24:\tlearn: 0.3272772\ttotal: 79.8ms\tremaining: 16ms\n",
      "25:\tlearn: 0.3216693\ttotal: 81.9ms\tremaining: 12.6ms\n",
      "26:\tlearn: 0.3171567\ttotal: 84.2ms\tremaining: 9.36ms\n",
      "27:\tlearn: 0.3145736\ttotal: 86.7ms\tremaining: 6.19ms\n",
      "28:\tlearn: 0.3129786\ttotal: 89.4ms\tremaining: 3.08ms\n",
      "29:\tlearn: 0.3098584\ttotal: 92.1ms\tremaining: 0us\n",
      "Splitting dataset (1000, 21) with test_size :0.2\n",
      "X_train: (800, 20)\n",
      "y_train: (800,)\n",
      "X_test: (200, 20)\n",
      "y_test: (200,)\n",
      "Learning rate set to 0.233364\n",
      "0:\tlearn: 0.6024436\ttotal: 1.75ms\tremaining: 50.9ms\n",
      "1:\tlearn: 0.5668051\ttotal: 2.98ms\tremaining: 41.8ms\n",
      "2:\tlearn: 0.5271043\ttotal: 4.45ms\tremaining: 40.1ms\n",
      "3:\tlearn: 0.4951954\ttotal: 6.09ms\tremaining: 39.6ms\n",
      "4:\tlearn: 0.4763013\ttotal: 7.34ms\tremaining: 36.7ms\n",
      "5:\tlearn: 0.4616869\ttotal: 8.75ms\tremaining: 35ms\n",
      "6:\tlearn: 0.4492145\ttotal: 9.98ms\tremaining: 32.8ms\n",
      "7:\tlearn: 0.4317846\ttotal: 11.3ms\tremaining: 31.2ms\n",
      "8:\tlearn: 0.4173873\ttotal: 12.6ms\tremaining: 29.5ms\n",
      "9:\tlearn: 0.4001422\ttotal: 13.9ms\tremaining: 27.7ms\n",
      "10:\tlearn: 0.3858756\ttotal: 15ms\tremaining: 25.9ms\n",
      "11:\tlearn: 0.3745713\ttotal: 16.1ms\tremaining: 24.2ms\n",
      "12:\tlearn: 0.3626961\ttotal: 17.7ms\tremaining: 23.1ms\n",
      "13:\tlearn: 0.3528154\ttotal: 18.8ms\tremaining: 21.5ms\n",
      "14:\tlearn: 0.3451026\ttotal: 20ms\tremaining: 20ms\n",
      "15:\tlearn: 0.3321441\ttotal: 21.3ms\tremaining: 18.6ms\n",
      "16:\tlearn: 0.3243953\ttotal: 23.5ms\tremaining: 17.9ms\n",
      "17:\tlearn: 0.3192040\ttotal: 24.6ms\tremaining: 16.4ms\n",
      "18:\tlearn: 0.3110163\ttotal: 25.7ms\tremaining: 14.9ms\n",
      "19:\tlearn: 0.3041756\ttotal: 26.8ms\tremaining: 13.4ms\n",
      "20:\tlearn: 0.3004645\ttotal: 28.4ms\tremaining: 12.2ms\n",
      "21:\tlearn: 0.2966280\ttotal: 29.5ms\tremaining: 10.7ms\n",
      "22:\tlearn: 0.2918658\ttotal: 30.6ms\tremaining: 9.3ms\n",
      "23:\tlearn: 0.2863376\ttotal: 31.7ms\tremaining: 7.93ms\n",
      "24:\tlearn: 0.2809065\ttotal: 33.5ms\tremaining: 6.71ms\n",
      "25:\tlearn: 0.2731167\ttotal: 35.5ms\tremaining: 5.47ms\n",
      "26:\tlearn: 0.2607883\ttotal: 37.5ms\tremaining: 4.17ms\n",
      "27:\tlearn: 0.2558800\ttotal: 39.2ms\tremaining: 2.8ms\n",
      "28:\tlearn: 0.2478930\ttotal: 40.9ms\tremaining: 1.41ms\n",
      "29:\tlearn: 0.2428016\ttotal: 42.5ms\tremaining: 0us\n"
     ]
    }
   ],
   "source": [
    "models = Models()\n",
    "transformer = Transformer()\n",
    "\n",
    "\n",
    "row_data = pd.read_csv('./dataset/project_data.csv', delimiter=';')\n",
    "# print(row_data)\n",
    "\n",
    "\n",
    "# Benchmark\n",
    "dataset_v0 = transformer.rename_columns(row_data)\n",
    "categorical_columns, categorical_columns_indexes = transformer.categorical_columns(dataset_v0) \n",
    "X_train_v0, X_test_v0, y_train_v0, y_test_v0 = transformer.train_test_split(dataset_v0, test_size=.2, shuffle=True)\n",
    "\n",
    "# - dataset_v0 && - [catboost_v0] untuned classifier on dataset_v0 data set (~75% accuracy)\n",
    "dataset_v0_catboost_v0 = models._catboost_classifier(X_train_v0,\n",
    "                                                     X_test_v0,\n",
    "                                                     y_train_v0,\n",
    "                                                     y_test_v0,\n",
    "                                                     cat_features=categorical_columns_indexes\n",
    "                                                    )\n",
    "\n",
    "# - dataset_v0 && - [catboost_v1] tuned classifier on dataset_v0 data set (~__% accuracy)\n",
    "# @TODO fulfill\n",
    "\n",
    "\n",
    "# Beating Benchmark\n",
    "dataset_v1 = transformer.rename_columns(row_data)\n",
    "dataset_v1 = transformer.data_cleaning(dataset_v1)\n",
    "X_train_v1, X_test_v1, y_train_v1, y_test_v1 = transformer.train_test_split(dataset_v1, test_size=.2, shuffle=True)\n",
    "\n",
    "# - dataset_v1 && - [catboost_v0] untuned classifier \n",
    "dataset_v1_catboost_v0 = models._catboost_classifier(X_train_v1,\n",
    "                                                     X_test_v1,\n",
    "                                                     y_train_v1,\n",
    "                                                     y_test_v1,\n",
    "                                                     cat_features=[]\n",
    "                                                    )\n",
    "\n",
    "# - dataset_v1 && - [xgboost_classifier_v0] untuned classifier\n",
    "dataset_v1_xgboost_classifier_v0 = models._xgboost_classifier(X_train_v1,\n",
    "                                                              X_test_v1,\n",
    "                                                              y_train_v1,\n",
    "                                                              y_test_v1\n",
    "                                                             )\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75 0.725 0.775\n"
     ]
    }
   ],
   "source": [
    "print(dataset_v0_catboost_v0, dataset_v1_catboost_v0, dataset_v1_xgboost_classifier_v0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
